{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"dataset\"\n",
    "categories = ['Apple', 'Dianthus', 'Figs', 'Hibiscus', 'Rose']\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "def make_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(DATA_DIR, category)\n",
    "        label = categories.index(category)\n",
    "\n",
    "        for imgName in os.listdir(path):\n",
    "            imagePath = os.path.join(path, imgName)\n",
    "            image = cv2.imread(imagePath)\n",
    "\n",
    "            try:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                image = np.array(image, dtype=np.float32)\n",
    "\n",
    "                data.append([image, label])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    #         cv2.imshow('Image :: ',image)\n",
    "    #         break\n",
    "    #     break\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    print(len(data))\n",
    "    pik = open('data.pickle', 'wb')\n",
    "    pickle.dump(data, pik)\n",
    "    pik.close()\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    pick = open('data.pickle', 'rb')\n",
    "    data = pickle.load(pick)\n",
    "    pick.close()\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    feature = []\n",
    "    labels = []\n",
    "\n",
    "    for img, label in data:\n",
    "        feature.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    feature = np.array(feature, dtype=np.float32)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    feature = feature/255.0\n",
    "\n",
    "    return [feature, labels]\n",
    "\n",
    "\n",
    "make_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature, labels) = load_data()\n",
    "\n",
    "# print(load_data())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    feature, labels, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input([224, 224, 3])\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(\n",
    "    5, 5), padding='Same', activation='relu')(input_layer)\n",
    "\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(\n",
    "    3, 3), padding='Same', activation='relu')(pool1)\n",
    "\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(filters=96, kernel_size=(\n",
    "    3, 3), padding='Same', activation='relu')(pool2)\n",
    "\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv3)\n",
    "\n",
    "conv4 = tf.keras.layers.Conv2D(filters=96, kernel_size=(\n",
    "    3, 3), padding='Same', activation='relu')(pool3)\n",
    "\n",
    "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
    "\n",
    "flt1 = tf.keras.layers.Flatten()(pool4)\n",
    "\n",
    "dnl = tf.keras.layers.Dense(512, activation='relu')(flt1)\n",
    "out = tf.keras.layers.Dense(5, activation='softmax')(dnl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 22s 354ms/step - loss: 1.3496 - accuracy: 0.4437\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - 21s 350ms/step - loss: 1.1328 - accuracy: 0.5345\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 21s 351ms/step - loss: 0.9855 - accuracy: 0.6084\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 21s 346ms/step - loss: 0.7819 - accuracy: 0.6992\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 22s 363ms/step - loss: 0.6173 - accuracy: 0.7580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Model(input_layer, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size = 10, epochs = 5)\n",
    "model.save('mymodel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[1.7110984e-12 7.7514822e-05 1.6260873e-16 9.2666005e-07 9.9992156e-01]]\n",
      "\tRose ==> 99.99 Accuracy\n"
     ]
    }
   ],
   "source": [
    "from skimage import transform\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "model = tf.keras.models.load_model('mymodel.h5')\n",
    "# model.evaluate(x_test, y_test, verbose=1)\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/224\n",
    "    np_image = transform.resize(np_image, (224, 224, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "\n",
    "\n",
    "imageForPrediction = \"C:\\\\Users\\\\Jash\\\\Downloads\\\\pexels-pixabay-56866.jpg\"\n",
    "image = load(imageForPrediction)\n",
    "# y_proba = model.predict(image)\n",
    "# y_classes = tf.keras.np_utils.probas_to_classes(y_proba)\n",
    "\n",
    "predictions = model.predict(image)\n",
    "print(predictions)\n",
    "\n",
    "maxAcc = float(-(sys.maxsize - 1))\n",
    "pred = 'word'\n",
    "i = 0\n",
    "for label in categories:\n",
    "    if(predictions[0][i] > maxAcc):\n",
    "        pred = label\n",
    "        maxAcc = predictions[0][i]\n",
    "    i = i + 1\n",
    "print(\"\\t%s ==> %.2f Accuracy\" % (label, 100*maxAcc))\n",
    "\n",
    "\n",
    "# prediction = model.predict(x_test)\n",
    "\n",
    "# plt.figure(figsize=(9,9))\n",
    "\n",
    "# for i in range(9):\n",
    "#     plt.subplot(3,3,i+1)\n",
    "#     plt.imshow(x_test[i])\n",
    "#     plt.xlabel('Actual: '+categories[y_test[i]]+'\\n'+'Predicted: '+categories[np.argmax(prediction[i])])\n",
    "\n",
    "#     plt.xticks([])\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed06ce79c699b2a8635fb6ba08f3407056cfa8a68ae6f7430e3be2442f7c3982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
